\begin{frame}[fragile]
  \frametitle{Deep Reinforcement Learning}
  \begin{itemize}
  \item Value Based
    \begin{itemize}
    \item Learnt Value Function
    \item Implicit Policy(e.g. $\epsilon - greedy$)
    \end{itemize}
  \item Policy Based
    \begin{itemize}
    \item No Value Function
    \item Learnt Policy
    \end{itemize}
  \item Actor Critic
    \begin{itemize}
    \item Learnt Value Function
    \item Learnt Policy
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{SVM}
  Hinge Loss + Kernel Method = SVM

  Sigmoid+Cross Entropy performs better than sigmoid+square loss, when negative
  value is very large. The training speed is faster than latter.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Ref}
  \begin{enumerate}
    Machine Learning: Extract information from data for making better decisions.

    Deep learning: finding a fuction to map features to labels.
    
  \item NIPS2015: http://www.iro.umontreal.ca/~bengioy/talks/DL-Tutorial-NIPS2015.pdf
  \end{enumerate}
\end{frame}